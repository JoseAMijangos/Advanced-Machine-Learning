{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jose Mijangos<br>CST 463<br>Oct 10, 2018\n",
    "# MNIST Classification with Voting\n",
    "## Introduction\n",
    "The MNIST dataset is a collection hand written numbers stored as tuples of pixel values. Each instance is labeled with the digit it represents, so the data is suited for classification.<br>\n",
    "We will be using the MNIST dataset to test our own voting classifier with logistic regression, random forest, and SVM as base predictors. We will also compare our voting classifier's accuracy to that of its base predictors.\n",
    "## Imported Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Machine Learning\n",
    "We retrieve a condensed version of the MNIST dataset from sklearn then we store the independent features in X and the labels in y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.load_digits()\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the data so that 70% of the instances are used as the training set and the rest are used as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier\n",
    "This classifier works by letting each base predictor vote which class an instance belongs to, and then predicting the class that gets the most votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(random_state = 123)\n",
    "rnd_clf = RandomForestClassifier(random_state = 123)\n",
    "svm_clf = svm.LinearSVC(random_state = 123)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)], \n",
    "    voting='hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on Test Data\n",
    "We denote the accuracy of a classifier to be the number of correct classifications divided by the number of instances in the test data. Note that each classifier is trained and tested on the same sets of training and testing data. So if the accuracy of model A is greater than model B, we can infer that model A performs better than model B at classifying MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9629629629629629\n",
      "RandomForestClassifier 0.9537037037037037\n",
      "LinearSVC 0.95\n",
      "VotingClassifier 0.9648148148148148\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Out of just the base predictors, logistic regression performed  the best with an accuracy of about 0.962. Random forest is second with an accuracy of about 0.953. Linear SVM is third with an accuracy of about 0.950. Overall, all of the base predictors performed very well considering that this classification problem has ten possible classes.<br><br>\n",
    "Out of all the classifiers, the voting classifier scored the greatest accuracy at about 0.964. I believe this outcome is due to the diversity of the base predictors. The increase in accuracy is proof that voting can increase the performace of independent classifiers. However, the increase is very insignificant and also depends on the random state of the classifiers."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
